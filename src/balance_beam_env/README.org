* Balance Beam Environment

This is a custom toy environment for MARL conventions research built on the [[https://madrona-engine.github.io/][Madrona game engine]].

** Installation

If you have already followed the instructions from the [[file:../../README.md][main README]], Balance Beam should already be installed. Otherwise, follow the following directions:

#+begin_src bash
  conda create -n madrona python=3.10
  conda activate madrona
  pip install torch numpy tensorboard

  git clone --recurse-submodules https://github.com/bsarkar321/madrona_rl_envs
  mkdir build && cd build
  cmake ..
  make -j
  cd ..

  pip install -e .
#+end_src

#+begin_quote
On some systems, you may need to specify the cuda toolkit directory for cmake as follows:

#+begin_src bash
  cmake -D CUDAToolkit_ROOT=/usr/local/cuda-12.0 ..
#+end_src
#+end_quote

** Testing

*** Correctness

For testing correctness, ensure that the madrona conda environment is active and you are in the scripts directory.

*For all of the following commands, the last line should be "Error rate: 0.0"*

Verify that gym installation passes tests:
#+begin_src bash
  python balance_example.py --num-envs 32 --verbose --validation --asserts --use-baseline
#+end_src

Verify that CPU version passes tests:
#+begin_src bash
  python balance_example.py --num-envs 32 --verbose --validation --asserts --use-cpu
  python balance_example.py --num-envs 1000 --verbose --validation --asserts --use-cpu
#+end_src

Verify that debug GPU version passes tests (note: remove /tmp/bugbalancecache if it exists):
#+begin_src bash
  MADRONA_MWGPU_KERNEL_CACHE=/tmp/bugbalancecache python balance_example.py --num-envs 32 --verbose --validation --asserts --debug-compile
  MADRONA_MWGPU_KERNEL_CACHE=/tmp/bugbalancecache python balance_example.py --num-envs 1000 --verbose --validation --asserts --debug-compile
#+end_src

Verify that optimized GPU version passes tests (note: remove /tmp/balancecache if it exists):
#+begin_src bash
  MADRONA_MWGPU_KERNEL_CACHE=/tmp/balancecache python balance_example.py --num-envs 32 --verbose --validation --asserts
  MADRONA_MWGPU_KERNEL_CACHE=/tmp/balancecache python balance_example.py --num-envs 1000 --verbose --validation --asserts
#+end_src

*** Performance

After validating correctness, we can determine the simulation throughput (in terms of steps * worlds / sec). Note that, in general, throughput increases as the number of environments increases.

To test the baseline (gym python implementation), run the following command. Note that Python's multiprocessing library may limit the number of environments you can create; for my system, the optimal throughput was at 32 environments.
#+begin_src bash
  python balance_example.py --num-envs 32 --use-baseline
#+end_src

To test the madrona versions for cpu and gpu, run the following commands:
#+begin_src bash
  python balance_example.py --num-envs 32 --use-cpu
  MADRONA_MWGPU_KERNEL_CACHE=/tmp/balancecache python balance_example.py --num-envs 32
#+end_src

When testing using 8 cores of an AMD EPYC 7402 Processor, an A40 GPU, and 64 GB RAM, I get the following performance numbers:
| num-envs | baseline | madrona cpu | madrona gpu |
|----------+----------+-------------+-------------|
|       32 | 2800     |       79500 |      131000 |
|      100 | 2900     |      224000 |      404000 |
|     1000 | -        |      920000 |     3900000 |
|    10000 | -        |      771000 |    36500000 |
|   100000 | -        |     1173591 |   209000000 |
|  1000000 | -        |     1200000 |   399000000 |

** Training

You can train agents using cleanrl's PPO implementation modified to use these new environments. In particular, you can use balance_train.py for decentralized training or balance_train_single.py for centralized training.

You can also use MAPPO using train/trainer.py with balance as the environment name.
